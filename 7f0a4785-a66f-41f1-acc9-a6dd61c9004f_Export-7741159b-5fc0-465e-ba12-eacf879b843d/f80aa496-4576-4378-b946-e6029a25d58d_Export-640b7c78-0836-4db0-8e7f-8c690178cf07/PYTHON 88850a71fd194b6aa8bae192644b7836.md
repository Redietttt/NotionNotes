# PYTHON

```python
print('hello world') 
```

```python
# comment in python --- no multi line comment
```

```python
print(type(name))
print(type(age))
print(type(name))
OP
<class 'str'>
<class 'int'>
<class 'str'>

```

```python
student_list = ['hanna','jo', 'dave', 'sami']
print(type(student_list))
print(student_list[1])

student_list.append("hailu") --- adds hailu
student_list.insert(3,'alex') --- adds alex on 3rd
```

tuple â€”- cant be manipulated

```python
name = ('hanna','jo', 'dave', 'sami')
print(type(name))
```

set

```python
names = ['hanna','jo', 'dave', 'sami']
height = int (1.78) #casting or changing variable
```

dictionary

```python
student_info = { 'name':'hanna',
                'age':'12',
                'sec':'B',
                'height':1.3,
                'skills':['java','js','python']
                }
print(student_info['height'])
```

looping

```python
for i in range(0,12):
    print(i)
    print('hello')

for index, value in enumerate(student_list):
print(index)
print(value)]
```

ifelse

```python
if age > 18:
        print('adult')

    elif ( age > 18):
        print('under age')
        
    else: 
        print('error')
```

## function

```python
def greet():
    print('hello world')

def greet_with_name(name):
    print('hello' + name)   
#or
def greet_with_name(name):
print(f'hello{name}')
```

to call the functions

```python
greet()
greet_with_name('hanna', age =56)

#default argument
def greet_with_name(name , age, last_name ='kebede'):
    print(f'hello{name} age:{age} last name:{last_name}')
```

positional argument

keyword argument

default argument

string format ion using f string

data scraping 

from ye hager west website

then send the data to telegram

```python
import requests
from bs4 import BeautifulSoup

# Define the URL of the webpage to scrape
url = '<https://www.example.com>'

# Send a GET request to the URL
response = requests.get(url)

# Parse the HTML content of the webpage using BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Find and extract the desired data from the webpage
data = soup.find('div', class_='data-container').text

# Print the scraped data
print(data)

```